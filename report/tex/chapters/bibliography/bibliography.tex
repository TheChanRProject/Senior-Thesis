\doublespacing
\setlength{\parindent}{1cm}

Abe, T., Kobayashi, T., and Imai, S., 1995. Harmonics tracking and pitch extraction based on instantaneous frequency, International Conference on Acoustics, Speech, and Signal Processing, ICASSP-95., Vol. 1. IEEE.
Ale Koretzky, 2019. Audio AI: isolating vocals from stereo music using Convolutional Neural Networks. Accessed at https://towardsdatascience.com/audio-ai-isolating-vocals-from-stereo-music-using-convolutional-neural-networks-210532383785
Chelpa, L. M., 1991. “A fuzzy set theoretic framework towards computer generation of alap in Hindustani music”, NITR, Mumbai.
Chordia P, Rae A., 2008. Understanding emotion in raag: an empirical study of listener responses. Computer Music Modeling and Retrieval. Sense of Sounds. 110- 24.
Chordia, P., and Rae, A., 2007. “Raag recognition using Pitch-class and pitch-class dyad distributions”, Proc. of ISMIR,pp. 431-436.
CompMusic Dataset 2019. Accessed at https://compmusic.upf.edu/node/328
Govindarajan M., 2013. Sentiment analysis of movie reviews using hybrid method of naive Bayes and genetic algorithm. International Journal of Advanced Computer Research. 3(4):139-45
Gulati, S., and Rao, P., 2011. ”A Survey of raag recognition techniques and improvement to the state of the art”, Sound and Music Computing.
Harte, C., Sandler, M., \& Gasser, M. (2006). Detecting Harmonic Change in Musical Audio. In Proceedings of the 1st ACM Workshop on Audio and Music Computing Multimedia (pp. 21-26). Santa Barbara, CA, USA: ACM Press. doi:10.1145/1178723.1178727.
Hindustani Classical Music, 2019. Accessed at https://en.wikipedia.org/wiki/Hindustani_classical_music
Kumar, V., Pandya, H., Jawahar, C. V., 2014. ``Identifying ragas in indian music'', International Conference on Pattern Recognition.
Librosa, 2019. Latest 0.6.2 documentation Accessed at https://librosa.github.io/librosa/
McFee, B., et. al., 2015. ``librosa: Audio and music signal analysis in python'', Proceedings of the 14th Python in Science Conference.
Pandey, G., Mishra, C., and Ipe, P., 2003. “Tansen: A system for automatic raga identification” Proc. of Indian International Conference on Artificial Intelligence, pp. 1350-1363.
Pendekar, R., Mahajan, S. P., and Mujumdar, R., 2013. “Harmonium Raga Recognition,” International journal of Machine learning and Computing, vol.3, No.4, August.
Raaga 2019, Accessed at https://en.wikipedia.org/wiki/Raga.
Ram Avtar Vir, 1999. “Theory of Indian music”, Pankaj Publications, New Delhi.
Schoerkhuber, C., and Klapuri, A., 2010. “Constant-Q transform toolbox for music processing”, 7th Sound and Music Computing Conference, Barcelona, Spain.
Sharma, H, and Bali, R.S., 2015. “Comparison of ML classifiers for Raga recognition”, International Journal of Scientific and Research Publications, October ,Volume 5.
Sharma, P., 2018. A Comprehensive Tutorial to learn Convolutional Neural Networks from Scratch by Analytics Vaidya accessed at https://www.analyticsvidhya.com/blog/2018/12/guide-convolutional-neural-network-cnn/
Shetty, S., and Achary, K., 2009. ”Raga mining of Indian music by extracting arohana-avarohana pattern”, International Journal of Recent trends in Engineering, vol.1, no.1.
Smith, J.O., 2011 ``Sinusoidal Peak Interpolation'', in Spectral Audio Signal Processing, https://ccrma.stanford.edu/~jos/sasp/Sinusoidal_Peak_Interpolation.html, online book, 2011 edition, accessed 2015-06-15.
Sridhar, R., and Geetha, T., 2009. “Raga identification of carnatic music for music information retrieval”, International Journal of Recent Trends in Engineering, vol.1, no.1, pp.571-574.
Stevens, et. al., 1937. A scale for the measurement of the psychological magnitude pitch. The Journal of the Acoustical Society of America 8, no. 3, pp. 185-190.
Tzanetakis, G., Cook, P., 2002. Musical genre classification of audio signals. IEEE Transactions on Speech and Audio Processing. 10(5):293-302.
Vaska JS, Sowjanya AM., 2015. Clustering diabetics data Using M-CFICA. International Journal of Advanced Computer Research. 5(20):327-33.
Young, S et. al., 1997. The HTK book. Vol. 2. Cambridge: Entropic Cambridge Research Laboratory.
Scikit-Sound, 2019. Accessed at https://github.com/thomas-haslwanter/scikit-sound
